"""ç›®æ ‡å¯¼å‘æ¨¡å¼"""
from typing import Dict, List
import time
import copy
from core.vlm_service import get_vlm_service
from core.vega_service import get_vega_service
from tools import get_tool_executor
from prompts import get_prompt_manager
from config.settings import Settings
from core.utils import app_logger, get_spec_data_count


class GoalOrientedMode:
    """ç›®æ ‡å¯¼å‘æ¨¡å¼"""
    
    def __init__(self):
        self.vlm = get_vlm_service()
        self.vega = get_vega_service()
        self.tool_executor = get_tool_executor()
        self.prompt_mgr = get_prompt_manager()
    
    def execute(self, user_query: str, vega_spec: Dict, 
                image_base64: str, chart_type, context: Dict = None, 
                benchmark_mode: bool = False) -> Dict:
        """æ‰§è¡Œç›®æ ‡å¯¼å‘åˆ†æžï¼ˆæŒ‰DashScopeæ ‡å‡†å¤šè½®å¯¹è¯æ ¼å¼ï¼‰"""
        if benchmark_mode:
            app_logger.info("ðŸŽ¯ Benchmark mode enabled: ANSWER field will be required in final iteration")
        system_prompt = self.prompt_mgr.assemble_system_prompt(
            chart_type=chart_type,
            mode="goal_oriented",
            include_tools=True,
            benchmark_mode=benchmark_mode
        )
        
        # ä»Žcontextè¯»å–messagesåŽ†å²ï¼ˆå¦‚æžœæœ‰ï¼‰
        messages = context.get('goal_oriented_messages', []) if context else []
        iterations = context.get('goal_oriented_iterations', []) if context else []
        
        # å¦‚æžœæ˜¯æ–°ä¼šè¯ï¼Œåˆå§‹åŒ–ç¬¬ä¸€æ¡useræ¶ˆæ¯
        if len(messages) == 0:
            messages.append({
                "role": "user",
                "content": [
                    {"text": f"è¯·åˆ†æžè¿™ä¸ªè§†å›¾ï¼Œç”¨æˆ·çš„åˆ†æžç›®æ ‡æ˜¯ï¼š{user_query}"},
                    {"image": f"data:image/png;base64,{image_base64}"}
                ]
            })
        
        # ä¿å­˜åŽŸå§‹ vega_specï¼Œç”¨äºŽ reset_view å·¥å…·
        original_vega_spec = copy.deepcopy(vega_spec)
        
        current_spec = vega_spec
        current_image = image_base64
        
        for iteration in range(Settings.MAX_GOAL_ORIENTED_ITERATIONS):
            # ðŸ“Š æ—¥å¿—ï¼šæ‰“å°messagesç»“æž„
            app_logger.info(f"iteration {iteration+1} - messages count: {len(messages)}")
            for idx, msg in enumerate(messages):
                role = msg['role']
                content_items = len(msg.get('content', []))
                has_image = any('image' in c for c in msg.get('content', []))
                app_logger.info(f"  æ¶ˆæ¯{idx}: role={role}, items={content_items}, å«å›¾ç‰‡={has_image}")
            
            # VLMè°ƒç”¨
            response = self.vlm.call(messages, system_prompt, expect_json=True)
            #å¦‚æžœè°ƒç”¨å¤±è´¥
            if not response.get("success"):
                app_logger.error(f"iteration {iteration+1} VLM failed: {response.get('error', 'Unknown')}")
                
                # è®°å½•å¤±è´¥çš„è¿­ä»£
                iterations.append({
                    "iteration": iteration + 1,
                    "success": False,
                    "error": response.get('error', 'Unknown'),
                    "timestamp": time.time()
                })
                break
            
            # å…³é”®ï¼šç›´æŽ¥è¿½åŠ VLMè¿”å›žçš„assistantæ¶ˆæ¯ï¼ˆæŒ‰DashScopeæ ‡å‡†ï¼‰
            decision = response.get("parsed_json", {})
            assistant_message = {
                "role": "assistant",
                "content": [{"text": response.get("content", "")}]  # VLMåŽŸå§‹è¾“å‡ºæ–‡æœ¬
            }
            messages.append(assistant_message)
            
            # ðŸ“Š æ—¥å¿—
            tool_info = decision.get('tool_call', {}).get('tool', 'None') if decision.get('tool_call') else 'None'
            achieved = decision.get('goal_achieved', False)
            app_logger.info(f"iteration {iteration+1} VLM decision: tool={tool_info}, goal_achieved={achieved}")
            
            # è®°å½•è¿­ä»£
            iteration_record = {
                "iteration": iteration + 1,
                "success": True,
                "timestamp": time.time(),
                "decision": decision,
                "vlm_raw_output": response.get("content", ""),  # ä¿å­˜VLMåŽŸå§‹è¾“å‡º
                "images": [current_image],
                "analysis_summary": {
                    "key_insights": decision.get("key_insights", []),
                    "reasoning": decision.get("reasoning", "")
                }
            }
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æˆç›®æ ‡
            if decision.get("goal_achieved", False):
                iterations.append(iteration_record)
                app_logger.info(f"Goal achieved at iteration {iteration + 1}")
                break
            
            # æ‰§è¡Œå·¥å…·
            if decision.get("tool_call"):
                tool_call = decision["tool_call"]
                tool_name = tool_call["tool"]
                tool_params = tool_call.get("params", {})
                tool_params['vega_spec'] = current_spec
                # åªæœ‰éœ€è¦contextçš„å·¥å…·æ‰ä¼ é€’
                if tool_name in ('reset_view', 'undo_view'):
                    tool_params['context'] = context
                
                tool_result = self.tool_executor.execute(tool_name, tool_params)
                
                # ä¿å­˜å·¥å…·æ‰§è¡Œè®°å½•ï¼ˆæŽ’é™¤vega_specé¿å…åºåˆ—åŒ–é—®é¢˜å’Œæ•°æ®å†—ä½™ï¼‰
                iteration_record["tool_execution"] = {
                    "tool_name": tool_name,
                    "tool_params": {k: v for k, v in tool_params.items() if k not in ('vega_spec', 'context')},
                    "tool_result": {k: v for k, v in tool_result.items() if k != 'vega_spec'}
                }
                
                if tool_result.get("success") and "vega_spec" in tool_result:
                    # æƒ…å†µ1ï¼šå·¥å…·æˆåŠŸä¸”è¿”å›žæ–°çš„vega_specï¼ˆä¿®æ”¹åž‹å·¥å…·ï¼‰
                    # å…ˆå°†æ—§ spec å…¥æ ˆï¼ˆæŽ’é™¤ reset/undoï¼‰
                    if tool_name not in ['reset_view', 'undo_view']:
                        if context is not None:
                            history = context.setdefault("spec_history", [])
                            history.append(copy.deepcopy(current_spec))

                    current_spec = tool_result["vega_spec"]

                    # è‹¥ä¼šè¯å­˜åœ¨å¤§æ•°æ®ç®¡ç†å™¨ï¼ŒæŒ‰åŒºåŸŸè¡¥ç‚¹
                    current_spec = self._apply_data_manager(current_spec, context)
                    render_result = self.vega.render(current_spec)
                    
                    if render_result.get("success"):
                        current_image = render_result["image_base64"]
                        iteration_record["images"].append(current_image)
                        
                        # è¿½åŠ useræ¶ˆæ¯ï¼šå·¥å…·æˆåŠŸåé¦ˆ
                        success_msg = tool_result.get("message", "æ“ä½œå®Œæˆ")
                        messages.append({
                            "role": "user",
                            "content": [
                                {"text": f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸã€‚\n\nç»“æžœï¼š{success_msg}\n\nè¿™æ˜¯æ›´æ–°åŽçš„è§†å›¾ï¼š"},
                                {"image": f"data:image/png;base64,{current_image}"}
                            ]
                        })
                        
                        app_logger.info(f"Re-rendered chart after {tool_name}: {success_msg}")
                    else:
                        # æ¸²æŸ“å¤±è´¥
                        render_error = render_result.get('error', 'Render failed')
                        app_logger.error(f"Failed to render after {tool_name}: {render_error}")
                        iteration_record["success"] = False
                        
                        messages.append({
                            "role": "user",
                            "content": [
                                {"text": f"âŒ å·¥å…· {tool_name} æ‰§è¡ŒåŽæ¸²æŸ“å¤±è´¥ï¼š{render_error}\n\nå½“å‰è§†å›¾ï¼ˆæœªå˜åŒ–ï¼‰ï¼š"},
                                {"image": f"data:image/png;base64,{current_image}"}
                            ]
                        })
                
                elif tool_result.get("success"):
                    # æƒ…å†µ2ï¼šå·¥å…·æˆåŠŸä½†æ²¡æœ‰è¿”å›žvega_specï¼ˆåˆ†æžåž‹å·¥å…·ï¼Œå¦‚calculate_correlationï¼‰
                    analysis_msg = tool_result.get("message", str(tool_result))
                    messages.append({
                        "role": "user",
                        "content": [
                            {"text": f"âœ… å·¥å…· {tool_name} æ‰§è¡ŒæˆåŠŸã€‚\n\nåˆ†æžç»“æžœï¼š{analysis_msg}\n\nè§†å›¾æœªå˜åŒ–ï¼Œå½“å‰è§†å›¾ï¼š"},
                            {"image": f"data:image/png;base64,{current_image}"}
                        ]
                    })
                    
                    app_logger.info(f"Tool {tool_name} completed (analysis only): {analysis_msg}")
                
                else:
                    # æƒ…å†µ3ï¼šå·¥å…·æ‰§è¡Œå¤±è´¥
                    error_msg = tool_result.get("error", "Unknown error")
                    messages.append({
                        "role": "user",
                        "content": [
                            {"text": f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥ã€‚\n\né”™è¯¯åŽŸå› ï¼š{error_msg}\n\nè¯·é€‰æ‹©å…¶ä»–å¯ç”¨å·¥å…·ï¼Œæˆ–å¦‚æžœç›®æ ‡å·²è¾¾æˆï¼Œè®¾ç½® goal_achieved: trueã€‚\n\nå½“å‰è§†å›¾ï¼ˆæœªå˜åŒ–ï¼‰ï¼š"},
                            {"image": f"data:image/png;base64,{current_image}"}
                        ]
                    })
                    
                    iteration_record["success"] = False
                    app_logger.warning(f"Tool {tool_name} failed: {error_msg}")
            
            iterations.append(iteration_record)
        
        # ä¿å­˜messageså’Œiterationsåˆ°contextï¼ˆç”¨äºŽä¸‹æ¬¡è°ƒç”¨ï¼‰
        if context is not None:
            context['goal_oriented_messages'] = messages
            context['goal_oriented_iterations'] = iterations
        
        return {
            "success": True,
            "mode": "goal_oriented",
            "iterations": iterations,
            "final_spec": current_spec,
            "final_image": current_image
        }

    def _extract_region(self, spec: Dict) -> Dict:
        """ä»Ž spec ä¸­æŽ¨æµ‹ç¼©æ”¾åŒºåŸŸï¼ˆåŸºäºŽ encoding.scale.domainï¼‰ã€‚"""
        region = {}
        encoding = spec.get("encoding", {}) if isinstance(spec, dict) else {}
        x_enc = encoding.get("x", {}) if isinstance(encoding, dict) else {}
        y_enc = encoding.get("y", {}) if isinstance(encoding, dict) else {}

        def _parse_domain(dom):
            if isinstance(dom, list) and len(dom) == 2:
                try:
                    return float(dom[0]), float(dom[1])
                except Exception:  # noqa: BLE001
                    return None, None
            return None, None

        x_min, x_max = _parse_domain(x_enc.get("scale", {}).get("domain") if isinstance(x_enc.get("scale"), dict) else None)
        y_min, y_max = _parse_domain(y_enc.get("scale", {}).get("domain") if isinstance(y_enc.get("scale"), dict) else None)

        if x_min is not None or x_max is not None:
            region["x_min"] = x_min
            region["x_max"] = x_max
        if y_min is not None or y_max is not None:
            region["y_min"] = y_min
            region["y_max"] = y_max

        region["x_field"] = x_enc.get("field")
        region["y_field"] = y_enc.get("field")

        return region if any(v is not None for v in region.values()) else {}

    def _apply_data_manager(self, spec: Dict, context: Dict = None) -> Dict:
        """å¦‚æžœä¼šè¯æœ‰ data_managerï¼Œåˆ™æŒ‰åŒºåŸŸè¡¥ç‚¹åŽè¿”å›žæ–°çš„ specã€‚"""
        if not context:
            return spec

        data_manager = context.get("data_manager")
        session_id = context.get("session_id")
        if not data_manager or not session_id:
            return spec

        region = self._extract_region(spec)
        if not region:
            return spec

        try:
            current_count = get_spec_data_count(spec)
            new_values = data_manager.load_region(region)
            new_spec = copy.deepcopy(spec)
            new_spec.setdefault("data", {})["values"] = new_values
            app_logger.info(
                f"ðŸ” Region data loaded: {current_count} -> {len(new_values)} points "
                f"(region: x=[{region.get('x_min')}, {region.get('x_max')}], "
                f"y=[{region.get('y_min')}, {region.get('y_max')}])"
            )
            return new_spec
        except Exception as exc:  # noqa: BLE001
            app_logger.error(f"apply_data_manager failed: {exc}")
            return spec
