# æ‰¹é‡è¯„æµ‹ä½¿ç”¨æŒ‡å— (Batch Benchmark Guide)

## ğŸ“‹ ç®€ä»‹

`run_all_benchmarks.py` æ˜¯ AgenticVisual é¡¹ç›®çš„æ‰¹é‡è¯„æµ‹è„šæœ¬ï¼Œç”¨äºè‡ªåŠ¨åŒ–è¿è¡Œå¤šä¸ªå¯è§†åŒ–åˆ†æä»»åŠ¡ï¼Œæ”¯æŒå¤šæ¨¡å‹å¯¹æ¯”å’Œè¯¦ç»†çš„åˆ†æ•°æ±‡æ€»ã€‚

### ä¸»è¦ç‰¹æ€§
- âœ… **æ‰¹é‡ä»»åŠ¡æ‰§è¡Œ**ï¼šè‡ªåŠ¨éå†ç›®å½•ä¸‹æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
- âœ… **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒ 7 ä¸ªä¸»æµ VLM æ¨¡å‹ï¼ˆGPTã€Claudeã€Geminiã€Qwen ç­‰ï¼‰
- âœ… **ä»»åŠ¡ç­›é€‰**ï¼šæ”¯æŒæŒ‰åç§°æˆ–é€šé…ç¬¦ç­›é€‰ç‰¹å®šä»»åŠ¡
- âœ… **å¹¶å‘æ§åˆ¶**ï¼šå¯è°ƒèŠ‚å¹¶å‘æ•°æé«˜æ•ˆç‡
- âœ… **è‡ªåŠ¨è¯„ä¼°**ï¼šé›†æˆç»Ÿä¸€è¯„ä¼°å™¨ï¼ˆUnified Evaluatorï¼‰è‡ªåŠ¨æ‰“åˆ†
- âœ… **è¯¦ç»†æ±‡æ€»**ï¼šç”Ÿæˆå¤šç»´åº¦ç»Ÿè®¡æŠ¥å‘Š

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…ä¾èµ–å¹¶é…ç½® API Keyï¼š

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è®¾ç½® OpenRouter API Keyï¼ˆå¿…é¡»ï¼‰
$env:OPENROUTER_API_KEY="sk-or-v1-..."  # Windows PowerShell
export OPENROUTER_API_KEY="sk-or-v1-..." # Linux/Mac
```

### 2. åŸºæœ¬è¿è¡Œ

```bash
# æœ€ç®€å•çš„ç”¨æ³•ï¼šè·‘æ‰€æœ‰ä»»åŠ¡çš„æ‰€æœ‰æ¨¡å‹
python run_all_benchmarks.py benchmark_annotation_system/annotated_task/benchmark/

# æ¨èï¼šå…ˆå°æ‰¹é‡æµ‹è¯•
python run_all_benchmarks.py benchmark_annotation_system/annotated_task/benchmark/ --models qwen --task-filter 07_bar_cm_01
```

---

## ğŸ›ï¸ å‚æ•°è¯¦è§£

### ä½ç½®å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `tasks` | ä»»åŠ¡æ–‡ä»¶è·¯å¾„æˆ–ç›®å½• | `benchmark/tasks/` æˆ– `tasks/01.json` |

### æ¨¡å‹é€‰æ‹©

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | ç¤ºä¾‹ |
|------|------|--------|------|
| `--models` | é€‰æ‹©è¦è·‘çš„æ¨¡å‹ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ | å…¨éƒ¨7ä¸ªæ¨¡å‹ | `--models qwen` æˆ– `--models qwen claude gpt` |

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `gpt` - GPT-4/GPT-5
- `claude` - Claude 3.5/4
- `gemini` - Google Gemini
- `grok` - xAI Grok
- `qwen` - é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆæ¨èï¼Œå›½å†…å¯ç”¨ï¼‰
- `llama` - Meta Llama
- `mistral` - Mistral AI

### ä»»åŠ¡ç­›é€‰

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--task-filter` | æŒ‰æ–‡ä»¶åå‰ç¼€ç­›é€‰ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ | `--task-filter 07_bar 34_scatter` |
| `--task-pattern` | æŒ‰é€šé…ç¬¦æ¨¡å¼ç­›é€‰ | `--task-pattern "*_cm_*.json"` |

**ç­›é€‰ç¤ºä¾‹**ï¼š
```bash
# åªè·‘ç‰¹å®šå‡ ä¸ªä»»åŠ¡
--task-filter 07_bar_cm_01 34_scatter_cm_01 40_heatmap_cm_01

# åªè·‘æ˜ç¡®å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆcm = clear multiï¼‰
--task-pattern "*_cm_*.json"

# åªè·‘æ•£ç‚¹å›¾ä»»åŠ¡
--task-pattern "*scatter*.json"

# åªè·‘3å¼€å¤´çš„ä»»åŠ¡
--task-pattern "3*.json"
```

### æ‰§è¡Œæ§åˆ¶

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ | å»ºè®® |
|------|------|--------|------|
| `--concurrency` | å¹¶å‘æ•°ï¼ˆåŒæ—¶è·‘å‡ ä¸ªä»»åŠ¡ï¼‰ | 1 | æµ‹è¯•æ—¶ç”¨1ï¼Œæ­£å¼è·‘ç”¨2-3 |
| `--retries` | å¤±è´¥é‡è¯•æ¬¡æ•° | 1 | ç½‘ç»œä¸ç¨³æ—¶è®¾ä¸º2-3 |

**å¹¶å‘å»ºè®®**ï¼š
- `--concurrency 1`ï¼šä¸²è¡Œæ‰§è¡Œï¼Œæœ€å®‰å…¨ï¼Œé€‚åˆè°ƒè¯•
- `--concurrency 2`ï¼šé€Ÿåº¦ç¿»å€ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
- `--concurrency 3`ï¼šé€Ÿåº¦æœ€å¿«ï¼Œå¯èƒ½æœ‰MCPå†²çªé£é™©

### è¾“å‡ºé…ç½®

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--output-dir` | ç»“æœè¾“å‡ºç›®å½• | `benchmark/results/batch` |
| `--log-dir` | è¿è¡Œæ—¥å¿—ç›®å½• | `benchmark/logs/batch` |

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èé¦–æ¬¡ä½¿ç”¨ï¼‰

```powershell
# Windows PowerShell
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen `
    --task-filter 07_bar_cm_01 34_scatter_cm_01 `
    --concurrency 1
```

**è¯´æ˜**ï¼šåªè·‘2ä¸ªä»»åŠ¡ï¼Œ1ä¸ªæ¨¡å‹ï¼Œä¸²è¡Œæ‰§è¡Œï¼Œç”¨äºéªŒè¯æµç¨‹æ˜¯å¦æ­£å¸¸ã€‚

### ç¤ºä¾‹ 2ï¼šå•æ¨¡å‹å…¨é‡è¯„æµ‹

```powershell
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen `
    --concurrency 3
```

**è¯´æ˜**ï¼šè·‘å…¨éƒ¨34ä¸ªä»»åŠ¡ï¼Œåªç”¨Qwenæ¨¡å‹ï¼ŒåŒæ—¶è·‘3ä¸ªåŠ é€Ÿã€‚

### ç¤ºä¾‹ 3ï¼šç‰¹å®šé¢˜å‹æ‰¹é‡æµ‹è¯•

```powershell
# åªè·‘æ˜ç¡®å¤šæ­¥éª¤ä»»åŠ¡ï¼ˆcm = clear multiï¼‰
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen `
    --task-pattern "*_cm_*.json" `
    --concurrency 2

# åªè·‘æ˜ç¡®å•æ­¥éª¤ä»»åŠ¡ï¼ˆcs = clear singleï¼‰
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen claude `
    --task-pattern "*_cs_*.json" `
    --concurrency 2
```

### ç¤ºä¾‹ 4ï¼šå¤šæ¨¡å‹æ¨ªå‘å¯¹æ¯”

```powershell
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen claude gemini `
    --task-filter 07_bar_cm_01 34_scatter_cm_01 40_heatmap_cm_01 `
    --concurrency 2
```

**è¯´æ˜**ï¼š3ä¸ªæ¨¡å‹ Ã— 3ä¸ªä»»åŠ¡ = 9ä¸ªä½œä¸šï¼Œå¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨ç›¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

### ç¤ºä¾‹ 5ï¼šå…¨æ¨¡å‹å®Œæ•´è¯„æµ‹ï¼ˆæœ€å…¨é¢ï¼‰

```powershell
python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --concurrency 3
```

**è¯´æ˜**ï¼š7ä¸ªæ¨¡å‹ Ã— 34ä¸ªä»»åŠ¡ = 238ä¸ªä½œä¸šï¼Œéœ€è¦æ•°å°æ—¶å®Œæˆã€‚

---

## ğŸ“Š è¾“å‡ºç»“æœè¯´æ˜

### å®æ—¶è¾“å‡º

è¿è¡Œæ—¶ä¼šæ˜¾ç¤ºè¿›åº¦ï¼š
```
[åŠ è½½] ä» benchmark_annotation_system/annotated_task/benchmark/ åŠ è½½ä»»åŠ¡...
[åŠ è½½] æ‰¾åˆ° 34 ä¸ªä»»åŠ¡
[ç­›é€‰] æŒ‰åç§°è¿‡æ»¤: 2/34 ä¸ªä»»åŠ¡
[ç­›é€‰] æœ€ç»ˆä»»åŠ¡æ•°: 2
  - 07_bar_cm_01.json
  - 34_scatter_cm_01.json

[æ¨¡å‹] å°†ä½¿ç”¨: qwen
[è¾“å‡º] ç»“æœç›®å½•: benchmark\results\batch\20260220_014200
[è¾“å‡º] æ—¥å¿—ç›®å½•: benchmark\logs\batch\20260220_014200

[å¯åŠ¨] å…± 2 ä¸ªä½œä¸š (ä»»åŠ¡Ã—æ¨¡å‹)
[é…ç½®] å¹¶å‘æ•°: 1, é‡è¯•: 1
============================================================
[1/2] qwen/07_bar_cm_01 ... OK [score=0.85]
[2/2] qwen/34_scatter_cm_01 ... OK [score=1.00]
```

### æœ€ç»ˆæ±‡æ€»

```
============================================================
 æ‰¹é‡è·‘åˆ†å®Œæˆ
============================================================
æ€»ä»»åŠ¡: 2, æˆåŠŸ: 2, å¤±è´¥: 0

[æŒ‰æ¨¡å‹ç»Ÿè®¡]
  qwen        : æˆåŠŸ 2, å¤±è´¥ 0
                å¹³å‡åˆ†: answer=0.92, tool=0.98, total=0.93

[æ€»ä½“å¹³å‡åˆ†]
  answer      : 0.925 (n=2)
  tool        : 0.980 (n=2)
  reasoning   : 0.950 (n=2)
  state       : 0.900 (n=2)
  total       : 0.935 (n=2)

[å¤±è´¥æ¸…å•]
  (æ— )
============================================================

[ä¿å­˜] è¯¦ç»†æ±‡æ€»å·²ä¿å­˜åˆ°: benchmark\results\batch\20260220_014200\summary.json
```

### ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„

```
benchmark/results/batch/20260220_014200/
â”œâ”€â”€ 07_bar_cm_01_qwen/
â”‚   â”œâ”€â”€ result.json              # æ¨¡å‹è¾“å‡ºç»“æœ
â”‚   â””â”€â”€ eval_result.json         # è¯„ä¼°åˆ†æ•°è¯¦æƒ…
â”œâ”€â”€ 34_scatter_cm_01_qwen/
â”‚   â”œâ”€â”€ result.json
â”‚   â””â”€â”€ eval_result.json
â””â”€â”€ summary.json                 # å®Œæ•´æ±‡æ€»ç»Ÿè®¡

benchmark/logs/batch/20260220_014200/
â”œâ”€â”€ 07_bar_cm_01_qwen.log        # è¿è¡Œæ—¥å¿—
â””â”€â”€ 34_scatter_cm_01_qwen.log
```

### summary.json ç»“æ„

```json
{
  "timestamp": "2026-02-20T01:42:00",
  "total": 2,
  "success": 2,
  "fail": 0,
  "by_model": {
    "qwen": {
      "success": 2,
      "fail": 0,
      "tasks": [...]
    }
  },
  "scores": {
    "overall": {
      "total": {"mean": 0.935, "count": 2}
    },
    "by_model": {
      "qwen": {
        "total": {"mean": 0.935, "count": 2}
      }
    }
  }
}
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: æç¤º "æœªæ‰¾åˆ°ä»»åŠ¡æ–‡ä»¶"
**åŸå› **ï¼šè·¯å¾„é”™è¯¯æˆ–ç›®å½•ä¸‹æ²¡æœ‰ `.json` æ–‡ä»¶
**è§£å†³**ï¼š
```bash
# æ£€æŸ¥è·¯å¾„
ls benchmark_annotation_system/annotated_task/benchmark/

# ç¡®è®¤æœ‰ .json æ–‡ä»¶
```

### Q2: æç¤º "Provider returned error" æˆ– 403
**åŸå› **ï¼šAPI Key æ— æ•ˆæˆ–æ¨¡å‹åœ°åŒºå—é™
**è§£å†³**ï¼š
- æ£€æŸ¥ `OPENROUTER_API_KEY` æ˜¯å¦è®¾ç½®æ­£ç¡®
- æŸäº›æ¨¡å‹ï¼ˆå¦‚ Claudeã€GPTï¼‰åœ¨å›½å†…å¯èƒ½å—é™ï¼Œå»ºè®®ç”¨ `qwen`

### Q3: ä»»åŠ¡å¤±è´¥ï¼ˆFAILï¼‰
**æ’æŸ¥æ­¥éª¤**ï¼š
1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`benchmark/logs/batch/æ—¶é—´æˆ³/ä»»åŠ¡å_æ¨¡å‹.log`
2. å¸¸è§åŸå› ï¼š
   - MCP å·¥å…·è°ƒç”¨é”™è¯¯
   - API è¶…æ—¶
   - æ ¼å¼è§£æé”™è¯¯

### Q4: å¦‚ä½•åªè·‘éƒ¨åˆ†ä»»åŠ¡æµ‹è¯•ï¼Ÿ
**è§£å†³**ï¼šä½¿ç”¨ `--task-filter` æˆ– `--task-pattern`
```bash
# åªè·‘å‰3ä¸ªä»»åŠ¡
--task-filter 07_bar_cm_01 07_bar_cs_01 07_bar_vm_01

# æˆ–æŒ‰æ¨¡å¼ç­›é€‰
--task-pattern "07_*.json"
```

### Q5: å¹¶å‘æ•°è®¾ç½®å¤šå°‘åˆé€‚ï¼Ÿ
**å»ºè®®**ï¼š
- è°ƒè¯•/å¼€å‘ï¼š`--concurrency 1`ï¼ˆä¸²è¡Œï¼Œæ˜“æ’æŸ¥ï¼‰
- æ­£å¼è·‘åˆ†ï¼š`--concurrency 2` æˆ– `3`ï¼ˆå¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§ï¼‰
- ä¸è¦è¶…è¿‡ 3ï¼Œå¯èƒ½å¼•å‘ MCP æœåŠ¡å™¨å†²çª

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### ç»“åˆå…¶ä»–å·¥å…·åˆ†æç»“æœ

```bash
# 1. æ‰¹é‡è·‘å®Œ
python run_all_benchmarks.py ... --models qwen

# 2. æŸ¥çœ‹ summary.json
cat benchmark/results/batch/æœ€æ–°æ—¶é—´æˆ³/summary.json

# 3. ç”¨ Python åˆ†æ
python -c "import json; d=json.load(open('summary.json')); print(d['scores']['overall'])"
```

### è‡ªåŠ¨åŒ–è„šæœ¬ç¤ºä¾‹

åˆ›å»º `run_batch.ps1`ï¼ˆWindowsï¼‰ï¼š
```powershell
$env:OPENROUTER_API_KEY = "sk-or-v1-..."

python run_all_benchmarks.py `
    benchmark_annotation_system/annotated_task/benchmark/ `
    --models qwen `
    --concurrency 3 `
    --output-dir results/qwen_full

Write-Host "æ‰¹é‡è·‘åˆ†å®Œæˆï¼"
```

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. æ—¥å¿—æ–‡ä»¶ï¼š`benchmark/logs/batch/æ—¶é—´æˆ³/*.log`
2. ç»“æœæ–‡ä»¶ï¼š`benchmark/results/batch/æ—¶é—´æˆ³/summary.json`
3. åŸå§‹ä»»åŠ¡æ–‡ä»¶ï¼š`benchmark_annotation_system/annotated_task/benchmark/*.json`

---

**æœ€åæ›´æ–°**ï¼š2026-02-20
**ç‰ˆæœ¬**ï¼šv2.0ï¼ˆé‡æ„ç‰ˆï¼‰
